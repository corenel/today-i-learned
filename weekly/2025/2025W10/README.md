# Technical Reading Summary - Week 10, 2025

The following is a summary of technical readings and inputs from Week 10 of 2025 (March 3rd to March 9th). For brevity, only titles, URLs, and LLM-generated summaries are listed for those interested in further reading. Further analysis and reflections are not included here.

- [Technical Reading Summary - Week 10, 2025](#technical-reading-summary---week-10-2025)
  - [Topics](#topics)
    - [Mac Studio (M4 Max or M3 Ultra)](#mac-studio-m4-max-or-m3-ultra)
    - [QwQ-32B](#qwq-32b)
    - [Manus](#manus)
  - [Interesting Things](#interesting-things)
    - [Generative AI](#generative-ai)
    - [Academic Research](#academic-research)
      - [Language Models](#language-models)
      - [Generative Models](#generative-models)
      - [Autonomous Driving](#autonomous-driving)
      - [Object Detection and Tracking](#object-detection-and-tracking)
      - [Semantic Segmentation](#semantic-segmentation)
      - [Scene Reconstruction](#scene-reconstruction)
      - [Depth Estimation](#depth-estimation)
      - [Other Papers](#other-papers)
    - [Software and Development](#software-and-development)
    - [Project and Team Management](#project-and-team-management)
    - [Knowledge Management](#knowledge-management)
    - [ACGN](#acgn)
    - [Podcasts](#podcasts)

## Topics

### Mac Studio (M4 Max or M3 Ultra)

> TL;DR: Mac Studio (M3 Ultra) with 512GB of unified memory offers better cost-performance than previously discussed options like NVIDIA Project DIGITS (128GB) and OrangePi AI Studio Pro (192GB). Its ecosystem is also well-established. It's a viable option for personal deployment of very large LLMs (concurrency is limited), especially MoE models (like DeepSeek V3/R1). However, consider whether such large models are truly necessary, if smaller models (like QwQ-32B) can meet your needs, and whether local deployment is actually required.

Mac Studio M3 Ultra, with its 512GB unified memory and optimized performance, is becoming a significant option for local deployment of large language models. Among various high-performance computing devices, can it truly meet the growing demands of AI developers?

The emergence of M3 Ultra has sparked a rethinking of the possibilities for local deployment of large models. Although Apple officially confirmed that the M4 Max chip does not have UltraFusion technology, hinting at the potential absence of M4 Ultra, the M3 Ultra still demonstrates unique value with its massive unified memory and relatively affordable cost per GB.

According to EXO Labs testing, two M2 Ultra 512GB devices connected via Thunderbolt 5 can run the full version of DeepSeek R1 (8-bit) model, achieving a speed of 20 tokens/s. In terms of cost-effectiveness, the 512GB memory of M3 Ultra is more attractive compared to solutions like NVIDIA Project DIGITS (128GB) and OrangePi AI Studio Pro (192GB).

It's also worth mentioning the quiet rise of modified RTX4090 versions. The 96GB VRAM version is expected to ship in May, priced around ¥29800, while the 48GB version is already available for about ¥23000.

- [No M4 Ultra Chip? Apple Confirms the M4 Max Chip Lacks UltraFusion](https://www.macrumors.com/2025/03/05/apple-confirms-m4-max-lacks-ultrafusion/): Apple is unlikely to release an M4 Ultra chip because the M4 Max chip lacks UltraFusion technology, and Apple officials hinted that not every generation of M-series chips will have an Ultra version.
  - The M4 Max chip lacks UltraFusion connectors, which is the most direct technical reason for the absence of M4 Ultra.
  - Apple's official statement "not every generation has an Ultra chip" hints at a shift in Apple's chip release strategy, and the absence of M4 Ultra may be part of this strategic adjustment.
  - The new Mac Studio is released, offering M4 Max and M3 Ultra chip options, but no M4 Ultra, which confirms the absence of M4 Ultra from a product perspective.
  > Apple told _Ars Technica_ that not every generation of M-series chips for Macs will include an "Ultra" chip. That seems like Apple indirectly confirming that it has no plans to release an M4 Ultra chip, and the M4 Max's lack of UltraFusion technology makes it even more likely there won't be an M4 Ultra chip.
- [10 万块的 Mac Studio M3 Ultra 实用性解析](https://phpstone.com/mac-studio-m3-ultra-preview/)：Mac Studio M3 Ultra is positioned as a high-performance desktop workstation. Although expensive, for specific professional users (especially AI developers and content creators), its extreme performance, massive memory, high-speed interfaces, and excellent software and hardware ecosystem integration make it uniquely practical in specific application scenarios.
  - Benchmark for local AI development workstations: M3 Ultra, with its 512GB unified memory and optimized MLX framework, becomes a powerful local AI development platform, especially suitable for large model fine-tuning and local deployment, reducing the threshold and cost of AI development.
  - Powerful tool for professional content creation: M3 Ultra's CPU, GPU, and media engine performance are significantly improved. Combined with Thunderbolt 5 interfaces and the macOS ecosystem, it becomes a powerful tool for high-load content creation such as 8K video editing and 3D rendering, improving the efficiency of professional workflows.
  - Value premium of the Apple ecosystem: The high price of Mac Studio M3 Ultra partially stems from the premium of the Apple ecosystem, including the ease of use of macOS, the convenience of the MLX framework, and seamless integration with professional software. These software and hardware synergy advantages are an important part of its "practicality."
- [EXO Labs](https://x.com/exolabs/status/1897360590987051041)
  > 2 x M2 Ultra 512GB ($18,000) connected with Thunderbolt 5 can run the full DeepSeek R1 (8-bit) with exo at 20 tok/sec.
- [[Thread by @alexocheema - Opinions of The M3 Ultra 512GB Mac Studio]]：Apple M3 Ultra Mac Studio, with its massive unified memory (512GB) and relatively low cost per GB, is very suitable for running large-scale sparse models, such as MoE models like DeepSeek V3/R1. Although its memory bandwidth is relatively low, this may be an advantage for certain types of AI model architectures (MoE and Modular Routing), especially in terms of cost-effectiveness. The author believes Apple's timing is excellent and appreciates Apple's ability to launch this product so quickly.
    - Apple M3 Ultra Mac Studio, with its 512GB of large memory and low cost per GB, becomes a cost-effective local solution for running large-scale sparse activation models (such as MoE models).
    - Apple made trade-offs in hardware design, sacrificing memory bandwidth (leading to lower memory refresh rates) in exchange for larger memory capacity and lower cost. This strategy is particularly suitable for memory capacity-sensitive but relatively low bandwidth demand sparse activation models.
    - Future AI hardware development trends may be more customized, requiring software and hardware co-optimization based on the characteristics of different model architectures. The design idea of M3 Ultra provides a case for this trend.
  > The M3 Ultra 512GB Mac Studio fits perfectly with massive sparse MoEs like DeepSeek V3/R1. 2 M3 Ultra 512GB Mac Studios with
  >
  > @exolabs is all you need to run the full, unquantized DeepSeek R1 at home.

Recently, there have also been rumors and tests of RTX4090 modified to 96GB VRAM (48GB version existed last year):
- [青龍聖者 on X: "4090 96gb verify."](https://x.com/bdsqlsz/status/1898307273967145350)
- 96GB version requires custom drivers (48GB modification does not)
- Manufacturers (Huarui Technology factory) on Xianyu reportedly will ship in May, 96GB currently priced at ¥29800 (uncertain if this is the actual price), 48GB version is in stock for ¥23000

### QwQ-32B

> TL;DR: Overall, it has similar thinking ability to `QwQ-Max-Preview`, and can solve the test questions relatively well (historical event verification and classical Chinese writing, social media post intention inference, medium-difficulty C++ code error correction, etc.). Considering it is only 32B, it is very suitable for local deployment. However, it still lags behind o1 pro, DeepSeek R1, etc. in reasoning ability.

The release of the QwQ-32B model marks a further breakthrough in open-source large models, especially with its outstanding performance in reasoning ability. What are the highlights of this model?

QwQ-32B is a 32B parameter reasoning model built by the Qianwen team based on reinforcement learning technology. Its performance is comparable to DeepSeek-R1 with 671 billion parameters (37 billion actually activated). Tests show that it performs excellently in tasks such as historical event verification, classical Chinese writing, social media intention inference, and medium-difficulty C++ code error correction.

Although there is still a gap compared to top models like Claude 3.7 Sonnet, o1 pro, and DeepSeek R1, considering its parameter scale of only 32B, the cost-performance ratio is extremely high. What is particularly gratifying is that QwQ-32B performs almost as well as the online Qwen-2.5-Max-Thinking-QwQ-Preview (only 0.2 points difference), indicating that Qianwen's open-source version is indeed of the same level as the online version.

For users with local deployment needs, QwQ-32B is currently one of the most cost-effective Chinese models that can be deployed on a single machine. The community has optimization deployment solutions provided by unsloth and other tools for reference.

- [[初步体验 QwQ-Max-Preview]]
- [QwQ-32B: Embracing the Power of Reinforcement Learning](https://qwenlm.github.io/blog/qwq-32b/)
  > Large-scale Reinforcement Learning (RL) has the potential to surpass traditional pre-training and post-training methods to improve model performance. Recent research shows that reinforcement learning can significantly improve the reasoning ability of models. For example, DeepSeek R1 achieves state-of-the-art performance by integrating cold-start data and multi-stage training, enabling it to perform deep thinking and complex reasoning. This time, we explore the role of large-scale reinforcement learning (RL) in improving the intelligence of large language models, and are pleased to introduce our latest reasoning model QwQ-32B. This is a model with 32 billion parameters, whose performance is comparable to DeepSeek-R1 with 671 billion parameters (of which 37 billion are activated). This achievement highlights the effectiveness of applying reinforcement learning to powerful foundation models that have undergone large-scale pre-training. In addition, we have also integrated agent-related capabilities into the reasoning model, enabling it to perform critical thinking while using tools and adjust the reasoning process based on environmental feedback. We hope that our efforts can prove that a powerful foundation model superimposed with large-scale reinforcement learning may be a feasible path to general artificial intelligence.
  >
  > We conducted large-scale reinforcement learning based on cold start. In the initial stage, we specifically conducted RL training for mathematics and programming tasks. Unlike relying on traditional reward models, we provide feedback for math problems by verifying the correctness of the generated answers, and provide feedback for code by evaluating whether the generated code successfully passes test cases through a code execution server. As the training rounds progressed, the performance in both fields showed continuous improvement. After the first stage of RL, we added another RL targeting general capabilities. This stage uses a general reward model and some rule-based verifiers for training. We found that a small number of steps of general RL can improve other general capabilities without significantly degrading performance on math and programming tasks.
- [Qwen on X](https://x.com/Alibaba_Qwen/status/1897366093376991515)
  > Qwen2.5-Plus + Thinking (QwQ) = QwQ-32B .
- [A few hours with QwQ and Aider - and my thoughts](https://www.reddit.com/r/LocalLLaMA/comments/1j4p3xw/a_few_hours_with_qwq_and_aider_and_my_thoughts/)
  > Those benchmarks beating Deepseek R1 (full fat) are definitely bogus. This model is not in that tier. But it's basically managed to become three iterative prompts to Qwen32B and Qwen-Coder32B in a single prompt, which is absolutely incredible. I think a lot of folks will get use out of this model.
- [Recommended settings for QwQ 32B](https://www.reddit.com/r/LocalLLaMA/comments/1j4p1fb/recommended_settings_for_qwq_32b/)
  > See [generation_config.json](https://huggingface.co/Qwen/QwQ-32B/blob/main/generation_config.json):
  >
  > ```json
  > {
  >   "repetition_penalty": 1.0,
  >   "temperature": 0.6,
  >   "top_k": 40,
  >   "top_p": 0.95
  > }
  > ```
- [karminski-牙医](https://x.com/karminski3/status/1897776454647288222)
  > Qwen-QwQ-32B-BF16 currently scores 278.9 points in testing (Figure 1), surpassing DeepSeek-V3 in the ranking, but still far from DeepSeek-R1.
  >
  > But! It is only 0.2 points away from the online Qwen-2.5-Max-Thinking-QwQ-Preview! This means that Qianwen's open-source version this time is indeed of the online level! (Performance is similar to http://chat.qwen.ai, click Thinking (QwQ) in the lower left corner after entering)
  >
  > In other words, QwQ-32B is currently the most cost-effective model we can deploy on a single machine! As expected of Qianwen! Continuing the legend of Qwen-coder!
- [Tutorial: How to Run QwQ-32B effectively | Unsloth Documentation](https://docs.unsloth.ai/basics/tutorial-how-to-run-qwq-32b-effectively)
- [Structured outputs with QwQ 32B](https://www.boundaryml.com/blog/qwq-32b-function-calling)
- [Aider polyglot 测试](https://x.com/paulgauthier/status/1898063999553642635)
  > QwQ 32B as architect with Qwen 2.5 Coder Instruct as editor scored 26% on the aider polyglot benchmark. This is a step up from QwQ 32B alone. QwQ+Coder also had no editing errors, versus QwQ alone erroring on 1/3 of tasks.
- [Prompts for QwQ-32B](https://www.reddit.com/r/LocalLLaMA/comments/1j4v3fi/prompts_for_qwq32b/)
  > 3 options for QwQ system prompt: Low/Medium/High Reasoning Effort

### Manus

> TL;DR: Not new, cautiously optimistic, no deep moat.

Manus, as a highly anticipated new AI assistant, has sparked in-depth discussions about the competitive advantages of Agent products, but where exactly is its real moat?

The popularity of Manus indicates that there is a strong market demand for general-purpose Agent products, but its technical barriers may not be as high as imagined. From an interaction perspective, Manus is indeed innovative and can lower the user threshold, but its technical architecture is relatively easy to analyze and replicate, and it is difficult to form a technical barrier in the short term.

Industry experts point out that the lasting competitive advantage of Agentic AI products does not only come from the accumulation of the number of tools or AI intelligence, but is built on the "compound interest effect" of tools, data, and intelligence in three dimensions. In particular, the compound interest effect at the data level, and the knowledge management and organizational capabilities based on data accumulation, are the keys to building a long-term and difficult-to-replicate moat.

Community reaction has been rapid, with open-source alternatives such as autoMate, OpenManus, and OpenHands emerging, further confirming the limited nature of technical barriers. For startup teams, seizing a niche and rapid iteration may be more important strategies.

- [[Manus爆火的背后，Agentic AI产品如何构筑持久的竞争优势？]]：The lasting competitive advantage of Agentic AI products does not only come from the accumulation of the number of tools or AI intelligence, but is built on the "compound interest effect" of tools, data, and intelligence in three dimensions. Among them, the compound interest effect at the data level, and the knowledge management and organizational capabilities based on data accumulation, are the keys to building a long-term and difficult-to-replicate moat. The companies that ultimately win will be those that can understand and adapt to the co-evolution model of AI and humans, and establish sustainable collaboration mechanisms, rather than just those with the strongest technology.
    - Competitive advantage of Agentic AI originates from the compound interest effect: The compound interest effect of tools, data, and intelligence in three dimensions jointly constitutes the core competitiveness of Agentic AI products, rather than a single technological breakthrough.
    - Data and knowledge management are lasting moats: In the case where tools and intelligence are easily replicated, data accumulation, knowledge externalization, and organizational capabilities formed based on this are the keys to building long-term competitive barriers.
    - Co-evolution of AI and humans is the future trend: The competition of Agentic AI will eventually evolve into a competition of organizations' ability to adapt to the AI era. Companies that understand and establish a co-evolutionary collaboration mechanism between AI and humans will have an advantage.
- [[Manus 的护城河在哪里？]]：Manus, as an AI product, has significant innovation in user interaction, but due to the limitations of current models and data, it currently lacks a real moat. The author believes that although Manus is amazing in interaction design, its technical implementation principles are relatively easy to analyze and imitate. Long-term competitive advantage will depend on whether it can build barriers in model capabilities, data accumulation, and user experience.
    - Interaction innovation is a highlight, but technical implementation is easy to imitate. Manus's interaction method is amazing, reducing the user threshold, but its technical architecture is relatively easy to analyze and replicate, and it is difficult to form a technical barrier in the short term.
    - Moat needs to be built from multiple dimensions of model, data, and user experience. The long-term competitive advantage of AI products needs to rely on model capabilities, data accumulation, and unique user experience to build a moat. Single interaction innovation is not enough to support long-term development.
    - Seizing a niche and rapid iteration are important strategies. In the early stage of AI development, quickly launching products, seizing market niches, and continuously iterating to optimize user experience and accumulate data are key strategies for building long-term competitive advantages (the "occupy niche" viewpoint).
- [Thread by @xiaokedada](https://x.com/xiaokedada/status/1897552294616674767)
    > Although I don't have a Manus invitation code, I can get a general overview from https://manus.im/usecases. Some of my fragmented thoughts:
    >
    > 1. A great product. There are actually not many usable general-purpose Agent products on the market. There are more vertical products like Coding Agent, but Coding Agent is ultimately aimed at ordinary users. The interaction form has made formal innovations for ordinary users.
    >
    > 2. ChatGPT's free canvas is actually a bit like a general-purpose Agent form. If done well.
    >
    > 3. Essentially, it may still not deviate from Lilian's diagram (if you know something about Agent). There is not much innovation in the underlying technology. More is to enhance tool capabilities and interaction forms. Another idea of Agent is RL based Agent, like OpenAI Operator, which improves the ability of Tool Use through RL. This completely originates from the large language model itself. Manus does not seem to be this way.
    >
    > 4. There is a very interesting point. Manus lists a checklist before each operation, and then reviews the completed content after completing a todo, which is a bit like a new paradigm of Agent + workflow, and it made this process public, making Agent feel more like a person (learned from DeepSeek?). But this method is not original. For example, windsurf will forcibly Analyze the current directory before each operation.
    >
    > 5. Agent is in a state of unfamiliarity and unheard of for most people. I believe that every small step of Agent products today is a big step in the future.

Open Source Alternatives:
- [autoMate](https://github.com/yuruotong1/autoMate)
- [OpenManus](https://github.com/mannaandpoem/OpenManus)
- [OpenHands](https://github.com/All-Hands-AI/OpenHands)

## Interesting Things

### Generative AI

Generative AI technology continues to break boundaries, with new application scenarios and tools emerging endlessly. How to grasp the key developments in them?

The emergence of olmOCR solves the problem of PDF document content extraction and linearization, opening up new paths for large-scale use of PDF document data to train language models. Fine-tuned based on Qwen2-VL-7B-Instruct, its open source provides valuable resources for both academia and industry.

Regarding AI application cognition, the article "AI Won't Eat You" puts forward an important point of view: AI should be regarded as a tool, a kind of "labor protection equipment," helping humans free themselves from repetitive "troubles." True value and security come from one's own inner cognition and problem-solving ability, rather than fear of AI threats.

"Deep Research" as a popular concept is being promoted by major companies, but its technical essence is actually a "report generation system"—accepting user queries, using LLMs as agents to iteratively search and analyze information, and generate detailed reports. The article divides the implementation methods into untrained DAG and FSM methods, and trained end-to-end and large inference model methods.

Other noteworthy developments include FlowDown (AI conversation client application), LettuceDetect (RAG hallucination detection tool), Aya Vision 8B/32B (multimodal vision model in 23 languages), and Wan2.1 and HunyuanVideo-I2V video generation models.

- [[olmOCR - Unlocking Trillions of Tokens in PDFs with Vision Language Models]]：olmOCR effectively solves the problem of PDF document content extraction and linearization, opening up new avenues for large-scale use of PDF document data to train language models, and its open-source nature and low cost make it widely applicable.
  - PDF documents are a huge treasure trove of untapped text data: PDF documents contain trillions of tokens of high-quality text data, but due to format complexity, existing tools struggle to effectively extract and utilize them.
  - olmOCR combines VLM and "document anchoring" technology to achieve low-cost, efficient, and high-quality PDF text linearization: olmOCR effectively improves the performance of VLM in PDF text extraction through innovative "document anchoring" technology, and achieves cost-effectiveness far exceeding other tools.
  - Open-source olmOCR toolkit and dataset to promote research and application in the field of PDF document understanding: The open source of the olmOCR toolkit, `olmOCR-7B-0225-preview` model, and `olmOCR-mix-0225` dataset provides valuable resources for academia and industry, and promotes the popularization and development of PDF document understanding technology.
  - Note:
    - Fine-tuned based on Qwen2-VL-7B-Instruct, can be compared with Qwen2.5-VL and Mistral OCR
    - Note that its [Usage](https://huggingface.co/allenai/olmOCR-7B-0225-preview#usage) indicates that the model requires specified format input and processed prompts

- [[AI 不会吃掉你]]：AI will not replace or "eat" you. The anxiety about AI is largely manufactured by marketing, and true value and security come from one's own inner cognition and problem-solving abilities. AI should be regarded as a tool, a kind of "labor protection equipment," helping humans free themselves from repetitive "troubles" so that they can better focus on creative "problems" and "topics." The core is to keep the prefrontal cortex "turned on" for rational thinking, rather than being swayed by emotional marketing tactics.
  - AI is not a threat, but a tool: AI will not "eat" you, no need to panic excessively. It is essentially a tool that can be used by humans to solve problems, improve efficiency, and liberate creativity. AI should be viewed rationally, not demonized.
  - Be wary of "AI anxiety" marketing, maintain rational thinking: There are a lot of marketing tactics in the market that sell "AI anxiety," aiming to profit by exploiting people's fears. You should be vigilant, use rational thinking, and not be swayed by emotional marketing to make wise judgments and decisions.
  - The pursuit of inner value and meaning is the core: True value and security come from one's own inner cognition, ability, and problem-solving ability, as well as the pursuit of one's own value and meaning. AI cannot replace this inner sense of value. You should focus on improving your own value and meeting inner needs, rather than over-focusing on external "AI threats."
- [[The Differences between Deep Research, Deep Research, and Deep Research]]："Deep Research" as an emerging popular concept is currently widely promoted and applied, but its definition and technical implementation methods are not clear. The article aims to distinguish different types of "Deep Research" from a technical implementation perspective, and clarify the hype surrounding this concept, returning to its essence—a report generation system. The author believes that rather than a completely new breakthrough, it is more of a repackaging and marketing of the "report generation" concept in the AI engineering field in the past few years.
  - Rise of the "Deep Research" concept: From the end of 2024 to the beginning of 2025, companies such as Google (Gemini 1.5 Deep Research), OpenAI (Deep Research), Perplexity (Deep Research), DeepSeek, Alibaba (Qwen), and xAI have successively launched or promoted "Deep Research" or "Deep Search" functions.
  - Ambiguity of the definition of "Deep Research": Although various companies are promoting "Deep Research," there is no unified and clear definition in the industry regarding its specific meaning and technical implementation. Many open-source implementations have also emerged, further intensifying the confusion of concepts.
  - The essence of "Deep Research" is report generation: By analyzing the promotional language of various companies, the article extracts the core definition of "Deep Research": "Deep research is a report generation system that accepts user queries, uses large language models (LLMs) as agents to iteratively search and analyze information, and generates detailed reports as output." In the field of natural language processing (NLP), this is actually "report generation."
  - Multiple implementation methods of "Deep Research": The article divides the technical implementation of "Deep Research" into untrained DAG and FSM methods, and trained end-to-end and large inference model methods, and analyzes the characteristics and advantages and disadvantages of each method in detail, providing a clear framework for understanding the technical essence of "Deep Research."
- [FlowDown](https://flowdown.ai/en-US) ：A blazing fast and smooth client app for AI conversations. Switch between AI services or use local models on your device.
  - Note:
    - For LLM API Clients only, for macOS consider [ChatWise](https://chatwise.app/), for Windows users consider [Cherry Studio](https://github.com/CherryHQ/cherry-studio), for web version consider [Open WebUI](https://github.com/open-webui/open-webui).
    - For local running, consider [LM Studio](https://lmstudio.ai/) or [Ollama](https://ollama.com/), or directly use llama.cpp or MLX. For actual deployment, use [vLLM](https://github.com/vllm-project/vllm) and [SGLang](https://github.com/sgl-project/sglang).
    - For quantized models, GGUF can consider using [unsloth](https://huggingface.co/unsloth), [bartowski](https://huggingface.co/bartowski), MLX is the version of [mlx-community](https://huggingface.co/mlx-community).
- [[New Yorker Opinion - The Government Knows A.G.I. Is Coming]]：Artificial General Intelligence (AGI) is likely to arrive in the next two to three years, and the U.S. government (including the Biden and Trump administrations) is aware of this and is trying to prepare for the arrival of AGI. The article emphasizes the huge opportunities and challenges brought by AGI, especially in national security, economic competition, and the labor market, and calls on all sectors of society, especially government departments, to seriously consider and formulate response strategies.
  - Note: Chinese translation see [this webpage](https://baoyu.io/translations/ezra-klein-podcast-ben-buchanan.html), the article can only represent the views of Ben Buchanan, former AI advisor to the Biden administration.
- [Cursor+Claude 3.7 Sonnet一段话生成高保真app原型图的提示词](https://x.com/AlchainHust/status/1896878623539573023) and [使用建议](https://x.com/manateelazycat/status/1897344213479776361)
  - Note: Needs model + examples + later self-adjustment
  - Examples of using Claude 3.7 Sonnet also include [别再用AI写垃圾代码！4个技巧帮你用AI写出漂亮炫酷的应用](https://mp.weixin.qq.com/s/tUOAfd4OI56QxD94-0PPKw)
- [LettuceDetect](https://github.com/KRLabsOrg/LettuceDetect) is a lightweight and efficient tool for detecting hallucinations in Retrieval-Augmented Generation (RAG) systems. It identifies unsupported parts of an answer by comparing it to the provided context. The tool is trained and evaluated on the [RAGTruth](https://aclanthology.org/2024.acl-long.585/) dataset and leverages [ModernBERT](https://github.com/AnswerDotAI/ModernBERT) for long-context processing, making it ideal for tasks requiring extensive context windows.
- [Aya Vision 8B/32B](https://huggingface.co/collections/CohereForAI/c4ai-aya-vision-67c4ccd395ca064308ee1484)：Aya Vision is a state-of-the-art family of vision models that brings multimodal capabilities to 23 languages.
- [Wan2.1](https://github.com/Wan-Video/Wan2.1) and [HunyuanVideo-I2V](https://github.com/Tencent/HunyuanVideo-I2V)：In terms of simple testing, the instruction following of Wan2.1 for image-generated video is stronger than Hunyuan Video I2V, and it is said that NSFW content can be generated under specific prompts without fine-tuning.
- [[LLM Quantization Comparison]]：Quantization is a key technology for efficient deployment of large language models. It can reduce memory footprint and increase inference speed, but inevitably sacrifices some model quality. The article further points out that the impact of different quantization levels on model performance varies, and this impact also differs in different task types and hardware platforms. The final conclusion of the article emphasizes that choosing an appropriate quantization strategy requires trade-offs between speed, memory, and accuracy, and needs to be optimized and selected according to specific application scenarios and hardware conditions.
  - * Quantization is key to LLM deployment, but there is a trade-off between accuracy and efficiency: The article clearly points out that quantization is a necessary means for efficient deployment of large language models, which can significantly reduce memory footprint and increase inference speed. However, lower quantization precision usually leads to a decrease in model performance. Trade-offs between accuracy and efficiency are needed.
  - Quantization effect is affected by task type and model size: Experimental results show that different quantization levels have different degrees of impact on different task types. For example, in Coding and Data Analysis tasks, low-bit quantization leads to a significant drop in performance, while in Reasoning tasks, large models can still perform well under heavy quantization. This shows that the choice of quantization strategy needs to consider the specific task type and model size.
  - 4-bit quantization is currently a better balance point, hardware platform affects quantization effect: The article concludes that 4-bit quantization format provides a good balance between accuracy and efficiency, and is currently a more popular choice. At the same time, the hardware platform has a significant impact on the inference speed of quantized models. Server-level GPUs are more advantageous in processing large quantized models. This suggests that we need to consider the limitations and optimizations of hardware platforms when actually deploying quantized models.
  - Note: If using models converted by unsloth, the perceived Q5 generates better results than Q4 without significantly increasing VRAM usage
- [[A Practical Guide to Implementing DeepSearchDeepResearch]]：DeepSearch and DeepResearch represent the new standard of search technology in 2025. They significantly improve the accuracy and depth of search through iterative "search-read-reason" loops and the concept of "test-time compute," marking a paradigm shift in search from traditional fast but shallow retrieval to emphasizing accuracy and recall. Users are also gradually accepting longer waiting times in exchange for higher quality results. DeepSearch is an atomic building block that continuously iterates search, reading web pages, and reasoning until the best answer is found or the budget is exceeded. DeepResearch is built on DeepSearch, focusing on generating high-quality, readable long research reports. It breaks down reports into multiple chapters and applies DeepSearch to each chapter, and finally integrates all chapters to improve overall coherence.
  - DeepSearch/DeepResearch represents a paradigm shift in search: From fast and shallow retrieval to in-depth exploration that emphasizes accuracy and recall. Users accept longer waiting times in exchange for higher quality results.
  - "Test-time compute" is the key driving force: By investing more computing resources in the inference stage, such as CoT and Wait-injection, to enhance the reasoning ability of LLMs, is the core technical concept of DeepSearch/DeepResearch.
  - Iterative "search-read-reason" loop is the core mechanism of DeepSearch: By continuously iterating search, reading web pages, and reasoning until the best answer is found or the budget is exceeded, it overcomes the limitations of traditional RAG and multi-hop QA.
- [[交替直接差分学習法ADDifT(Alternating Direct Difference Training)の解説｜hakomikan]]：Proposes a new LoRA learning method called Alternating Direct Difference Training (ADDifT), which can significantly shorten the training time of differential learning, support synchronous learning of multiple image sets, and has the potential to be applied to various diffusion models. The article aims to introduce the principle, advantages, and preliminary experimental results of the ADDifT method, and look forward to its future development direction.
  - Direct Difference Training: ADDifT directly learns the difference in noise prediction between two images, avoiding the redundancy and inefficiency of traditional methods learning the absolute content of images.
  - Alternating Training: Alternating differential learning in both positive and negative directions offsets the learning of non-target differences and improves the accuracy of learning.
  - Scheduled Random Timesteps: To address the problem of uneven Timesteps distribution in small-step training, a planned random Timesteps selection strategy is proposed to improve the stability and efficiency of training.
- [[とうとう現れたSDXLの後継？CogView4-6Bを解説する]]：The most important argument of the article is that the emergence of CogView4-6B is a major turning point in the field of image generation AI after SDXL, because it is an open-source model that adopts the latest technology, has high performance, and uses the Apache-2.0 license. This breaks the slow progress and limited practicality in the field of image generation AI since Flux.1. The article believes that CogView4-6B is not only technically advanced, but also has great potential in commercial applications and further development, foreshadowing a new open-source trend in image generation AI.
- [[The Model is the Product  Vintage Data]]：The next stage of artificial intelligence (AI) development has arrived, "The model is the product." The author believes that current scientific research and market development trends all point in this direction, that is, the model itself will become the center of core value and business model, rather than just as the basis of applications. The article points out that the infinite expansion of general-purpose models has encountered bottlenecks, while "Opinionated training" models for specific tasks show amazing results, and inference costs are also greatly reduced. These factors jointly promote model providers to migrate upstream in the value chain, directly building end products, rather than just providing API interfaces.
- [prompt-optimizer](https://github.com/linshenkx/prompt-optimizer)：A prompt optimizer to help write high-quality prompts.
- [[Thread by @rao2z - RL is great but RL envy in LLMs may not be]]：Re-evaluation of the role of reinforcement learning (RL) in large language models (LLMs), and questioning the possibility of its being overemphasized in the success of models like DeepSeek R1. The author believes that R1's success may be more attributed to the capabilities of its foundation model and effective reward signals, rather than RL itself. He further suggests that in the context of R1, the difference between RL and supervised fine-tuning (SFT) may not be as significant as described in the paper, and may even be similar to the difference between stochastic gradient descent (SGD) and batch gradient descent (Batch). The author also questions the concept of "reasoning trajectory" and explores different forms of Markov Decision Process (MDP) in LLMs.
- [[Hallucinations (Confabulations) Document-Based Benchmark for RAG. Includes human-verified questions and answers.]]：Existing benchmarks for Retrieval-Augmented Generation (RAG) Large Language Model (LLM) hallucinations (Confabulation) are flawed, and more effective methods are needed to assess and reduce the frequency of LLMs hallucinating in RAG systems. The article proposes and introduces a new benchmark `confabulations`, focusing on evaluating the frequency of LLMs generating non-existent answers (hallucinations) when faced with misleading questions based on provided documents. This benchmark aims to more accurately measure the reliability of LLMs in RAG applications and help optimize RAG systems to reduce hallucinations.

### Academic Research

#### Language Models

- [[Token-Efficient Long Video Understanding for Multimodal LLMs]]：Proposes STORM (Spatiotemporal TOken Reduction for Multimodal LLMs) architecture, a new type of video multimodal large language model architecture, which aims to effectively integrate spatiotemporal dynamic information between the image encoder and the language model by introducing a temporal encoder based on the Mamba state space model, thereby improving the performance and efficiency of the model in long video understanding tasks. The STORM architecture and its supporting token compression strategies (including temporal pooling during training, spatial pooling, and temporal token sampling during testing) can achieve state-of-the-art performance in various long video understanding benchmarks while significantly reducing computational costs and inference latency, and outperform existing methods, especially achieving more than 5% performance improvement on the MLVU and LongVideoBench benchmarks.
- [[Words or Vision Do Vision-Language Models Have Blind Faith in Text?]]：Vision-language models (VLMs) have a phenomenon of "blind faith in text" when processing visual and textual information. When visual information and textual information are inconsistent, VLMs will disproportionately trust textual data, even if the text is wrong or misleading, which leads to a significant decline in the performance of the model in vision-centric tasks and triggers potential security risks.
  - "Blind faith in text" leads to performance degradation of VLMs in vision-centric tasks and may trigger security risks. Especially when textual information is corrupted or misleading, the accuracy of VLMs will be significantly reduced, which poses a potential threat in safety-critical application scenarios.
  - The "blind faith in text" phenomenon is affected by various factors, but it is difficult to completely solve it through simple instructions or expanding the model size. Influencing factors include instruction prompts, language model size, text relevance, token order, and unimodal certainty. Supervised fine-tuning (SFT) is an effective mitigation strategy, but more fundamental solutions still need to be continuously explored.
  - Note: Similar to previously sticking text such as "Don't Detect" on clothes, or other adversarial patterns to deceive target detection models.
- [[Using GRPO to Beat o1, o3-mini and R1 at "Temporal Clue" - OpenPipe]]：By using Group Relative Policy Optimization (GRPO) reinforcement learning method, small, open-source large language models (LLMs) can be trained to achieve or even surpass the performance level of some large proprietary models in logical reasoning tasks (taking the "Temporal Clue" puzzle as an example), while significantly reducing inference costs. In other words, the article proves that small open-source models can achieve performance comparable to or even exceeding large models in specific complex reasoning tasks through effective reinforcement learning training, and are more cost-effective.
- - [[Headroom for AI development – Machine Learning (Theory)]]：Current Transformer-based large language models (LLMs), although making significant progress, still have fundamental inefficiencies, especially in sample efficiency, representation efficiency, and long-range memory and planning capabilities. Compared with humans and animals, LLMs still have huge room for improvement. Future research should go beyond simply expanding existing models and explore more innovative architectures and methods.
- [[ClipGrader Leveraging Vision-Language Models for Robust Label Quality Assessment in Object Detection]]：Proposes a new method called ClipGrader, which utilizes vision-language models (VLMs), especially CLIP (Contrastive Language-Image Pre-training), to automatically and effectively evaluate the quality of bounding box annotations in object detection tasks. ClipGrader can not only evaluate the correctness of category labels, but also evaluate the spatial accuracy of bounding boxes, providing a scalable AI-assisted tool for annotation quality control and verification of large-scale object detection datasets.
- [[ABC Achieving Better Control of Multimodal Embeddings using VLMs]]：Proposes a new multimodal embedding model called ABC, which can more effectively fuse image features and natural language instructions by using the backbone network of vision-language models (VLMs), thereby achieving finer control over multimodal embedding representations. The authors believe that existing CLIP-based methods have limitations when dealing with visual tasks that require user instructions or have ambiguities, while the ABC model overcomes these problems by deeply integrating visual and linguistic information, and achieves excellent performance in multiple benchmarks. The core innovation lies in using the VLM architecture to achieve deep interaction between modalities, and improving the efficiency and flexibility of the model by decoupling pre-training and instruction fine-tuning methods.

#### Generative Models

- [[Simulating the Real World A Unified Survey of Multimodal Generative Models]]：To achieve general artificial intelligence (AGI), simulating the real world is crucial, but existing multimodal generative model research usually treats different dimensions (2D images, video, 3D, 4D) as independent fields, lacking systematic integration and cross-dimensional understanding. Therefore, this paper aims to build a unified framework to systematically review the applications and progress of multimodal generative models in real-world simulation from the perspective of data dimension growth (2D -> video -> 3D -> 4D), and provide guidance for future research.
- [[PhotoDoodle Learning Artistic Image Editing from Few-Shot Examples]]：Proposes a new image editing framework called PhotoDoodle, which aims to learn the unique style of artists through a few examples to achieve automatic photo doodling. PhotoDoodle can seamlessly superimpose decorative elements onto photos while maintaining background consistency and accurate capture of artistic style. The article emphasizes that PhotoDoodle solves the challenges faced by existing methods in photo doodling tasks, such as harmonious integration, background protection, and efficient style extraction.

#### Autonomous Driving

- [[UniMLVG Unified Framework for Multi-view Long Video Generation with Comprehensive Control Capabilities for Autonomous Driving]]：Proposes a unified framework called UniMLVG (Unified Framework for Multi-view Long Video Generation) for generating multi-view long videos with comprehensive control capabilities, especially for autonomous driving scenarios. The core conclusion of the article is that the UniMLVG framework can effectively generate high-quality, spatiotemporally consistent, and controllable multi-view long videos of autonomous driving scenes, and outperforms existing technologies in terms of generation quality and conditional control. To achieve this goal, UniMLVG innovatively adopts a multi-task, multi-condition, multi-stage training strategy and introduces an explicit viewpoint modeling method. Experimental results show that UniMLVG significantly outperforms existing methods in FID and FVD metrics, and also achieves leading levels in conditional compliance metrics.
- [[Dur360BEV A Real-world 360-degree Single Camera Dataset and Benchmark for Bird-Eye View Mapping in Autonomous Driving]]：Proposes the Dur360BEV dataset and a benchmark architecture, proving that bird's-eye view (BEV) maps for autonomous driving can be effectively generated using only a single spherical camera. The article aims to address the challenges of BEV generation in autonomous driving by reducing hardware complexity (using a single 360-degree camera instead of a multi-camera system), and shows that competitive performance can be achieved even with simplified sensor configurations.
  - Launch of Dur360BEV dataset, which is the first large-scale real-world single spherical camera autonomous driving dataset, filling the gap in sensor modalities in existing datasets, and providing important resources for single-camera BEV perception research.
  - Propose SI2BEV benchmark architecture, proving that BEV maps for autonomous driving can be effectively generated using only a single spherical camera, simplifying hardware setup and reducing system complexity and cost.
  - Innovative application of Focal Loss in BEV segmentation, effectively solving the serious category imbalance problem in BEV segmentation tasks, significantly improving segmentation performance, and providing new ideas for the optimization of BEV perception models.
- [[Deep Height Decoupling for Precise Vision-based 3D Occupancy Prediction]]：By introducing the Deep Height Decoupling (DHD) framework, the accuracy of vision-based 3D occupancy prediction can be significantly improved and reach the current optimal level. The article believes that in the 2D-to-3D view transformation process of existing methods, feature confusion is caused due to insufficient consideration of object height information, which limits prediction accuracy. The DHD framework effectively solves this problem by explicitly predicting and utilizing height prior knowledge.
  - Height decoupling is key. Traditional methods ignore the height distribution differences of objects in 2D-to-3D view transformation, resulting in feature confusion and limiting prediction accuracy. The DHD framework decouples the height map into multiple height intervals through the Mask Guided Height Sampling (MGHS) module, and performs mask projection to achieve height-aware feature sampling, effectively reducing feature confusion.
  - Synergistic feature aggregation improves representation ability. The DHD framework introduces the Synergistic Feature Aggregation (SFA) module, which synergistically aggregates depth-based and height-refined features through channel and spatial attention mechanisms, further improving feature representation ability and achieving more precise occupancy prediction.
- [[HazardNet A Small-Scale Vision Language Model for Real-Time Traffic Safety Detection at Edge Devices]]：Proposes HazardNet, a small vision language model (VLM), which is fine-tuned on the pre-trained Qwen2-VL-2B model and trained using the newly created HazardQA dataset. It can achieve efficient and real-time traffic safety event detection on edge devices, and its performance can surpass or be comparable to larger models, thereby contributing to improving urban traffic safety and management. The article emphasizes HazardNet's small scale, high efficiency, and deployment potential on edge devices, as well as its superior performance in traffic safety event detection.
  - HazardNet proves the feasibility of small-scale VLM for high-performance real-time traffic safety event detection on edge devices. By parameter-efficient fine-tuning of the Qwen2-VL-2B model, HazardNet achieves performance comparable to large models while maintaining a small model size, making it very suitable for resource-constrained edge device deployment.
  - The proposal of the HazardQA dataset fills the gap in VQA datasets in the field of traffic safety, providing new resources for training and evaluating traffic safety event detection models. The HazardQA dataset focuses on safety-critical scenarios and adopts a question-and-answer annotation form, which can better train models to understand and reason about traffic safety events.
  - Parameter-efficient fine-tuning methods (LoRA/QLoRA) are key technologies to achieve high performance on small-scale VLMs. By fine-tuning only a small number of parameters, LoRA/QLoRA significantly improves the performance of HazardNet while maintaining the efficiency of the model, verifying the effectiveness of parameter-efficient fine-tuning methods in resource-constrained scenarios.
- [[SegLocNet Multimodal Localization Network for Autonomous Driving via Bird’s-Eye-View Segmentation]]：Proposes a new multimodal localization network called SegLocNet, which achieves high-precision, robust, and generalizable autonomous vehicle localization without GNSS through bird's-eye view (BEV) semantic segmentation. The core conclusion of the article is that SegLocNet outperforms current state-of-the-art localization methods on the nuScenes and Argoverse datasets, and can effectively utilize high-definition (HD) and standard-definition (SD) maps to achieve precise vehicle self-localization in urban environments.

#### Object Detection and Tracking

- [[Omnidirectional Multi-Object Tracking]]：Proposes a new omnidirectional multi-object tracking (MOT) framework called OmniTrack, which aims to solve the problem that existing MOT algorithms perform poorly in panoramic images, and achieves state-of-the-art performance.
  - Propose OmniTrack framework: Aiming at the challenges of panoramic image multi-object tracking, the OmniTrack framework is innovatively proposed. The framework integrates three core components: Tracklet Management, FlexiTrack Instance, and CircularStatE Module, which effectively improves the performance of panoramic MOT.
  - Contribute QuadTrack dataset: To make up for the lack of panoramic MOT datasets, the QuadTrack dataset is released. The dataset has the characteristics of wide field of view, complex motion, and real scenes, providing a new benchmark for panoramic MOT research.
  - Achieve SOTA performance: Through a large number of experiments on the JRDB and QuadTrack datasets, it is proved that the OmniTrack framework has achieved state-of-the-art performance in panoramic MOT tasks, surpassing existing E2E and TBD methods.
- [[YOLO-MST Multiscale deep learning method for infrared small target detection based on super-resolution and YOLO]]：Proposes a new deep learning method for infrared small target detection called YOLO-MST, which significantly improves the accuracy and robustness of infrared small target detection by combining image super-resolution technology and multi-scale observation. The article finally concludes that the YOLO-MST method achieves detection performance superior to existing advanced methods on two public datasets (IRIS and SIRST), effectively solving the problems of missed detection, false alarms, and low accuracy of traditional methods and existing deep learning methods in complex backgrounds and small target detection.
- [[Locate Anything on Earth Advancing Open-Vocabulary Object Detection for Remote Sensing Community]]：Existing open-vocabulary object detection (OVD) models perform well on natural images, but their performance drops significantly in the field of remote sensing images due to the huge data domain gap. In order to promote the development of OVD in the remote sensing field, this paper proposes the "Locate Anything on Earth (LAE)" task, and for this purpose, it builds a large-scale remote sensing open-vocabulary object detection dataset LAE-1M, and the first foundation model LAE-DINO for the LAE task.
- [[VoxelNextFusion A Simple, Unified and Effective Voxel Fusion Framework for Multi-Modal 3D Object Detection]]：Proposes VoxelNextFusion, a simple, unified, and effective voxel fusion framework for multimodal 3D object detection. The framework aims to address the challenges encountered by existing voxel-based multimodal 3D object detection methods when fusing sparse point cloud features and dense image features, especially the problem of poor long-distance object detection performance. VoxelNextFusion effectively bridges the gap between sparse point clouds and dense images through the proposed P2-Fusion (Patch-Point Fusion) and FB-Fusion (Foreground-Background Fusion) modules, significantly improving the performance of 3D object detection, especially in difficult scenes and long-distance object detection.
  - Importance of P2-Fusion (Patch-Point Fusion): The article emphasizes the key role of the P2-Fusion module in solving the resolution mismatch between sparse point clouds and dense images. Through the Patch Fusion strategy, P2-Fusion can more fully utilize the semantic information and continuity of images, overcoming the limitations of one-to-one projection, and is one of the key factors for performance improvement.
  - Contribution of FB-Fusion (Foreground-Background Fusion): The article points out that the FB-Fusion module can effectively suppress background noise and further improve detection performance by distinguishing foreground and background features and enhancing foreground features. The introduction of the FB-Fusion module enables VoxelNextFusion to focus more on important target features and reduce background interference, thereby improving detection accuracy.
  - Note: In the future, it may be possible to consider how to more effectively utilize the contextual information and time information of images
- [[MI-DETR An Object Detection Model with Multi-time Inquiries Mechanism]]：The cascaded decoder architecture in existing DETR-like models limits the ability of object queries to learn comprehensive information from image features. In order to fully utilize image features to cope with object detection challenges in complex scenes, this paper proposes a new decoder architecture MI-DETR with Parallel Multi-time Inquiries (MI) mechanism. MI-DETR enables object queries to learn more comprehensive information through a parallel multi-time inquiry mechanism, thereby improving object detection performance.
- [[RTGen Real-Time Generative Detection Transformer]]：Proposes a new real-time generative object detector called RTGen (Real-Time Generative Detection Transformer), which overcomes the limitations of traditional object detectors relying on predefined categories, and achieves significant inference speed improvement while maintaining high accuracy. The core innovation of RTGen is the integration of a non-autoregressive language model into the object detection decoder, realizing parallel processing of objects and text information, thus surpassing existing methods in both speed and performance.
- [[The Common Objects Underwater (COU) Dataset for Robust Underwater Object Detection]]：Existing terrestrial object detection datasets have limited application in underwater environments, so specialized underwater object detection datasets are needed to improve the performance of underwater object detection models. To solve this problem, the authors created and released a new underwater object dataset called COU (Common Objects Underwater), and proved that models trained using the COU dataset perform better in underwater object detection tasks than models trained using only terrestrial datasets.

#### Semantic Segmentation

- [[DSV-LFS Unifying LLM-Driven Semantic Cues with Visual Features for Robust Few-Shot Segmentation]]：Combining large language model (LLM)-driven semantic prompts with dense matching of visual features can significantly improve the robustness and performance of few-shot semantic segmentation (FSS), making it perform better when generalizing to new categories and dealing with various scenes. The framework proposed in the article, called DSV-LFS, overcomes the limitations of traditional FSS methods in incomplete and biased feature representation by fusing semantic knowledge obtained from LLMs and spatial information obtained from visual matching, and finally achieves state-of-the-art performance.
  - Fusing LLM semantic knowledge and visual feature matching is key to improving the robustness and performance of FSS. The core argument of the article is that by combining the category semantic information provided by LLMs and the spatial information provided by visual dense matching, the limitations of traditional FSS methods can be overcome, and the model's generalization ability on new categories and segmentation accuracy in complex scenes can be significantly improved.
  - The DSV-LFS framework effectively realizes the fusion of LLM semantic knowledge and visual features through a dual prompting mechanism (semantic prompt + visual prompt). The proposed DSV-LFS framework generates semantic prompts through the Class Semantic Encoder module, visual prompts through the Dense Matching Module, and uses the Prompt-based Decoder module for fusion and segmentation, forming an end-to-end effective solution.
  - Experimental results show that the DSV-LFS framework has achieved state-of-the-art FSS performance on multiple benchmark datasets and demonstrated good cross-domain generalization ability. Through experiments on the PASCAL-5<sup>i</sup> and COCO-20<sup>i</sup> datasets and in cross-domain scenarios, the performance of the DSV-LFS framework is significantly better than existing methods, verifying its effectiveness and superiority.
- [[COARSE Collaborative Pseudo-Labeling with Coarse Real Labels for Off-Road Semantic Segmentation]]：Proposes a semi-supervised domain adaptation framework called COARSE to solve the problem of semantic segmentation in unstructured off-road environments, especially in the case of lack of densely annotated data and only coarsely annotated data. The COARSE framework significantly improves the performance and generalization ability of off-road semantic segmentation by combining coarse in-domain labels and dense out-of-domain labels, utilizing the powerful feature extraction ability of pre-trained visual Transformer (DINOv2), and complementary pixel-level decoder (PixelDecoder) and patch-level decoder (PatchDecoder), and through a collaborative pseudo-labeling strategy.
  - The COARSE framework effectively solves the problem of low utilization of coarsely annotated data in off-road semantic segmentation. Through a collaborative pseudo-labeling strategy, combining coarse in-domain labels and dense out-of-domain labels, model performance is significantly improved, reducing the dependence on expensive densely annotated data.
  - The combination of complementary decoders (PixelDecoder & PatchDecoder) and DINOv2 pre-trained model is the key to the success of the COARSE framework. DINOv2 provides powerful domain generalization features, and complementary decoders utilize these features from different perspectives, and generate high-quality pseudo-labels through disagreement strategy.
  - Pseudo-label density can be used as a new heuristic method to guide data annotation and model iterative optimization. High pseudo-label density areas may indicate areas where model prediction uncertainty is high, which are worth prioritizing for manual annotation to achieve more efficient data utilization and model improvement.
- [[Label-Efficient LiDAR Panoptic Segmentation]]：Proposes a new method called L3PS (Limited-Label LiDAR Panoptic Segmentation), which can significantly reduce the dependence of LiDAR panoptic segmentation on a large amount of annotated data. By using a small amount of annotated images to generate high-quality 3D panoptic pseudo-labels, and effectively training the LiDAR segmentation network, it finally achieves a balance between annotation efficiency and segmentation performance.
  - Label efficiency first: The core argument is to greatly reduce the dependence of LiDAR panoptic segmentation on expensive and time-consuming point cloud annotation, and turn to more cost-effective image annotation.
  - 2D-3D pseudo-label conversion: The key viewpoint is to use advanced 2D image panoptic segmentation models and pre-trained models to generate high-quality 2D pseudo-labels, and convert them into 3D point cloud pseudo-labels through projection as the basis for training data.
  - Geometry information-driven 3D refinement: The key viewpoint is to significantly improve the quality of initial 3D pseudo-labels by designing a 3D refinement module, fully utilizing the geometric characteristics and time-series information of point clouds, making them sufficient to train high-performance LiDAR segmentation models.
  - Note: Similar to the annotation generation method of [[OVM3D-Det - Training an Open-Vocabulary Monocular 3D Object Detection Model without 3D Data]]
- [[Golden Cudgel Network for Real-Time Semantic Segmentation]]：Proposes Golden Cudgel Network (GCNet), a new network for real-time semantic segmentation, designed to improve both performance and inference speed. The core innovation of GCNet lies in its self-expanding and self-shrinking characteristics: in the training phase, the network expands its own structure to enhance learning ability; in the inference phase, the network shrinks and simplifies the structure to increase speed, and the performance is hardly affected. This design overcomes two common problems in existing real-time semantic segmentation models: the decrease in inference speed caused by multi-path modules and the dependence on high-performance teacher models. The final conclusion of the article is that, through experimental verification, GCNet outperforms current state-of-the-art real-time semantic segmentation models in terms of both performance and speed on datasets such as Cityscapes, CamVid, and Pascal VOC 2012.
  - Note: The table of inference speed comparison is quite detailed and can be used for reference.
- [[BEVMOSNet Multimodal Fusion for BEV Moving Object Segmentation]]：By fusing multimodal data from cameras, LiDAR, and radar, and using the Multimodal Deformable Cross-Attention (MDCA) mechanism for sensor fusion, the accuracy and robustness of Bird's-Eye-View (BEV) Moving Object Segmentation (MOS) can be significantly improved, especially in low-light, night, and harsh weather conditions.
- [[Segment-Level Road Obstacle Detection Using Visual Foundation Model Priors and Likelihood Ratios]]：Using segmentation-level features of Visual Foundation Model (VFM) (especially Segment Anything Model, SAM), combined with Likelihood Ratio method, road obstacle detection can be effectively and robustly performed, and it outperforms existing pixel-level methods in component-level metrics, while eliminating the need for manual threshold selection.
- [[RMP-SAM Towards Real-Time Multi-Purpose Segment Anything]]：Proposes a new real-time multi-purpose segmentation model called RMP-SAM (Real-Time Multi-Purpose Segment Anything), which aims to solve the balance problem between real-time performance and multi-task versatility of existing segmentation methods, and achieves the best trade-off between speed and accuracy in three sub-tasks: interactive segmentation, panoptic segmentation, and video instance segmentation.
- [[Attention-Guided Integration of CLIP and SAM for Precise Object Masking in Robotic Manipulation]]：By innovatively integrating CLIP (Contrastive Language-Image Pretraining), SAM (Segment Anything Model), and Grad-CAM (Gradient-based Class Activation Mapping), and combining gradient attention mechanism and customized dataset for fine-tuning, the accuracy of object masks in robot manipulation can be significantly improved, especially in specific fields such as convenience store commodity recognition. This integrated method can overcome the limitations of existing methods on domain-specific data, and provide more accurate object mask input for robot systems, thereby achieving more accurate and adaptive object manipulation.

#### Scene Reconstruction

- [[EvidMTL Evidential Multi-Task Learning for Uncertainty-Aware Semantic Surface Mapping from Monocular RGB Images]]：Existing monocular RGB image semantic surface mapping methods often produce overconfident semantic predictions and are affected by sparse and noisy depth perception, resulting in inconsistent map representations. To solve this problem, the article proposes EvidMTL and EvidKimera frameworks, which achieve uncertainty-aware semantic surface mapping by introducing Evidential Multi-Task Learning, thereby improving the accuracy and consistency of the map and enhancing the reliability of robot decision-making.
- [[GaussianGraph 3D Gaussian-based Scene Graph Generation for Open-world Scene Understanding]]：Existing 3D Gaussian Splatting (3DGS)-based scene understanding methods have limitations in semantic segmentation accuracy and spatial reasoning ability. To solve these problems, the article proposes the GaussianGraph framework, which enhances the scene understanding ability of 3DGS by integrating adaptive semantic clustering and scene graph generation. GaussianGraph can achieve more accurate semantic segmentation and stronger spatial reasoning, thereby providing a more robust solution for complex scene understanding and interaction.
  - Note: Mainly focus on static scenes
- [[No Parameters, No Problem 3D Gaussian Splatting without Camera Intrinsics and Extrinsics]]：Proposes a novel joint optimization method that can train 3D Gaussian Splatting (3DGS) models without camera intrinsics and extrinsics. The article aims to solve the problem that existing 3DGS technology over-relies on accurately pre-calculated camera parameters (such as focal length and camera pose), and further relax input requirements, so that high-quality scene reconstruction and new viewpoint synthesis can be completed using only image collections.
  - Joint optimization framework: By jointly optimizing camera intrinsics, extrinsics, and 3DGS model parameters, the synergistic improvement of camera parameter estimation and scene representation learning is achieved, overcoming the bottleneck of camera parameter preprocessing in traditional methods.
  - Gradient derivation and mixed training strategy: Theoretically derives the gradient of camera intrinsics (focal length) and incorporates it into the backpropagation optimization process. At the same time, introduces global trajectory information and mixed training strategy (tracking Gaussian kernels and ordinary Gaussian kernels) to improve the stability and accuracy of training.
- [[LiteGS A High-Performance Modular Framework for Gaussian Splatting Training]]：LiteGS is a high-performance, modular Gaussian Splatting training framework that significantly improves training efficiency and usability while maintaining or improving rendering quality. LiteGS overcomes the limitations of traditional 3DGS implementations through modular design, optimized algorithms, and dual API support, making it more suitable for rapid prototyping and production environments.
  - Modular design is key to improving the flexibility and customizability of the 3DGS framework. LiteGS makes it easier for users to customize and extend by breaking down the rendering process into modular components, accelerating the iteration and prototyping of new algorithms.
  - Fine-grained optimization for GPU architecture is key to improving the training efficiency of 3DGS. LiteGS fully utilizes the parallel computing power and memory management mechanism of GPUs through clustering, compression, sparse gradients, multi-batch reduction, and other technologies, significantly improving training speed.
  - Dual API support (Python & CUDA) can balance the needs of rapid prototyping and production environment performance. LiteGS provides Python API for rapid experiments and prototype development, and CUDA API for performance-critical applications, meeting the needs of different scenarios.
- [[Evolving High-Quality Rendering and Reconstruction in a Unified Framework with Contribution-Adaptive Regularization]]：Proposes a unified framework called CarGS, which effectively solves the inherent conflict between high-quality rendering and precise surface reconstruction through Contribution-adaptive Regularization, thereby achieving state-of-the-art rendering quality and reconstruction accuracy while maintaining real-time speed and minimal storage space. The article aims to prove that by learning the adaptive contribution of Gaussian primitives, an efficient and effective unified model can be built, overcoming the difficult problem of trade-offs between rendering and reconstruction in traditional methods.
  - Contribution-adaptive Regularization is key to solving the inherent conflict in the unified framework of rendering and reconstruction. The article points out that it is difficult for existing methods to balance rendering and reconstruction in a unified framework. The core problem is that there is a conflict in the contribution of Gaussian primitives to the two tasks. By learning adaptive contributions, this conflict can be effectively alleviated and performance can be improved.
  - The proposed CarGS model achieves SOTA rendering and reconstruction performance under a unified framework through a lightweight module (Lite-Geo) and geometry-guided densification strategy, while maintaining high efficiency. The core contribution of CarGS lies in integrating geometric regularization knowledge into a compact MLP, and combining it with a geometry-guided densification strategy, and finally achieves significant advantages in performance, efficiency, and storage space.
  - Covariance is a property crucial to geometric reconstruction in the contribution of Gaussian primitives. Through experimental analysis, the article reveals the key role of covariance in geometric reconstruction, which provides a theoretical basis for the CarGS model to design a contribution-adaptive regularization module for covariance.
- [[DoF-Gaussian Controllable Depth-of-Field for 3D Gaussian Splatting]]：Proposes the DoF-Gaussian framework, a controllable Depth-of-Field (DoF) method for 3D Gaussian Splatting (3D-GS), which aims to solve the problems that existing 3D-GS methods cannot effectively handle shallow depth-of-field input images and lack controllable depth-of-field effects. The core conclusion of the article is that DoF-Gaussian can effectively reconstruct scenes from shallow depth-of-field input images and achieve controllable depth-of-field effects by introducing a lens imaging model based on geometric optics principles, and combining scene depth prior adjustment and defocus-to-focus adaptive strategy, while maintaining the real-time rendering efficiency of 3D-GS. Experimental results show that DoF-Gaussian outperforms existing methods in defocus deblurring and controllable depth-of-field rendering.
  - Lens imaging model is key to achieving controllable depth-of-field. The article clearly points out that the transition from pinhole camera model to lens camera model is the core of achieving DoF control. By parameterizing lens parameters such as aperture size and focal length and making them learnable, DoF-Gaussian can simulate real depth-of-field effects and allow users to interactively adjust depth-of-field parameters, which surpasses the capabilities of previous 3D-GS methods.
  - Depth prior and defocus-to-focus adaptive strategy are guarantees for performance improvement. In order to cope with the geometric reconstruction challenges brought by shallow depth-of-field images and the difference between ideal CoC and real CoC, the article innovatively proposes depth prior adjustment and defocus-to-focus adaptive strategy. These strategies effectively improve the accuracy of scene geometry and enhance the performance of defocus deblurring, ensuring the robustness and high-quality rendering effect of DoF-Gaussian when processing real shallow depth-of-field images.
- [[MUSt3R Multi-view Network for Stereo 3D Reconstruction]]：Proposes MUSt3R (Multi-view Network for Stereo 3D Reconstruction), a new type of multi-view network for stereo 3D reconstruction. MUSt3R achieves state-of-the-art performance in multiple 3D downstream tasks, including visual odometry without camera calibration, relative pose estimation, scale and focal length estimation, 3D reconstruction, and multi-view depth estimation. It can run efficiently in offline and online scenarios, and is suitable for SfM and visual SLAM applications.
  - Note: TL;DR make DUSt3R symmetric and iterative+multi-layer memory mechanism->multi-view DUSt3R
- [[MTReD 3D Reconstruction Dataset for Fly-over Videos of Maritime Domain]]：Proposes and validates a new maritime domain 3D reconstruction benchmark dataset MTReD (Maritime Three Dimensional Reconstruction Dataset), and a new perceptual similarity metric DiFPS (DinoV2 Features Perception Similarity) for evaluating the geometric consistency and visual completeness of maritime scene 3D reconstruction. The article experimentally proves the limitations of existing methods in maritime scene 3D reconstruction, and demonstrates the effectiveness of the MTReD dataset and DiFPS metric, as well as the positive effect of preprocessing methods on improving reconstruction quality.
- [[Efficient Perspective-Correct 3D Gaussian Splatting Using Hybrid Transparency]]：By combining hybrid transparency rendering method and perspective-corrected 3D Gaussian splat evaluation method, the rendering efficiency and visual quality of 3D Gaussian Splatting (3DGS) can be significantly improved, while solving the problems of perspective distortion and depth sorting errors in traditional 3DGS that lead to artifacts, and finally achieving faster, more stable, and higher quality real-time rendering. The method proposed in the article achieves significant improvements in training and rendering speed while maintaining or improving image quality, and solves the problem of multi-view consistency.
- [[FlexDrive Toward Trajectory Flexibility in Driving Scene Reconstruction and Rendering]]：Current 3D Gaussian Splatting-based driving scene reconstruction and rendering technology has high rendering quality on pre-recorded vehicle trajectories, but the quality drops significantly at viewpoints deviating from the trajectory. To solve this problem, the article proposes the FlexDrive framework. The core idea is to generate high-quality supervision signals for out-of-path viewpoints through Inverse View Warping (IVW) technology, and combine Depth Bootstrap (DB) strategy to obtain accurate depth information, thereby significantly improving the reconstruction and rendering quality of out-of-path viewpoints and maintaining the competitiveness of in-path viewpoints. Finally, FlexDrive aims to achieve trajectory flexibility in driving scene reconstruction and rendering, making it more suitable for practical driving simulator applications.

#### Depth Estimation

- [[Prompting Depth Anything for 4K Resolution Accurate Metric Depth Estimation]]：Proposes Prompt Depth Anything (PromptDA), a new paradigm for metric depth estimation. By using low-cost LiDAR as a prompt to guide depth foundation models, it achieves high-resolution (up to 4K) and accurate metric depth estimation. The core idea of the article is to regard metric depth estimation as a downstream task, and unlock its potential in accurate metric depth estimation by providing metric information prompts to depth foundation models.
  - Low-cost LiDAR as effective metric Prompt. The article verifies that low-cost LiDAR (such as iPhone LiDAR) can be used as an effective metric Prompt to guide depth foundation models to generate accurate metric depth maps, and overcome the scale ambiguity problem of monocular depth estimation.
  - Data pipeline and edge-aware loss are key to training PromptDA. In order to solve the problems of insufficient training data and low quality of real data annotation, the article proposes a scalable data pipeline (synthetic LiDAR simulation + real pseudo GT depth) and edge-aware loss function, which ensures the effective training and SOTA performance of PromptDA.

#### Other Papers

- [[AnyAnomaly Zero-Shot Customizable Video Anomaly Detection with LVLM]]：Proposes Customizable Video Anomaly Detection (C-VAD) technology and develops a model called AnyAnomaly to realize this technology. The core idea of C-VAD is to use user-defined text descriptions as the definition of abnormal events, thereby realizing zero-shot video anomaly detection without retraining the model for specific environments. The AnyAnomaly model performs well in C-VAD tasks and achieves competitive or even state-of-the-art performance on traditional video anomaly detection (VAD) benchmark datasets, especially surpassing traditional methods in terms of generalization ability.
- [[PokéChamp an Expert-level Minimax Language Agent]]：By combining large language models (LLMs) with minimax tree search, AI agents that reach expert level in complex, partially observable two-player zero-sum games (such as Pokémon battles) can be built without additional LLM training or task-specific fine-tuning. This argument is proved by introducing an agent called PokéChamp and experimentally verifying its excellent performance in Pokémon Gen 9 OU mode. PokéChamp uses LLMs to enhance the key modules of the minimax algorithm, enabling it to effectively utilize game history and human knowledge, thereby making better decisions in environments with huge search space and incomplete information.
- [[Ironies of Automation]]：The application of automation in industrial processes, although intended to replace manual operations, often increases rather than decreases the dependence and challenges for human operators in unexpected ways. Furthermore, the higher the degree of automation, the more important the key role of human operators may become. This is not because automation is unsuccessful, but because automated systems inevitably leave those complex, abnormal, and unexpected tasks that designers cannot or are unwilling to automate to human operators to handle.
  - Automation paradox: The higher the degree of automation, the more important the key role of human operators may become. Automation is intended to reduce human participation, but in fact leaves more complex and critical tasks to humans.
  - Skill degradation and monitoring difficulties: Automation leads to the degradation of operators' manual skills, but in abnormal situations, operators are required to have superb skills for manual takeover. At the same time, the automation system itself also brings monitoring difficulties, and it is difficult for humans to effectively monitor the operating status of the automation system for a long time.
  - Human-machine collaboration is the future direction: The classic method of "human-machine function allocation" is not enough to cope with the challenges brought by automation. In the future, it is necessary to develop a more complete human-machine collaboration model to use computers to support human operators' decision-making and operations, and jointly cope with complex systems and abnormal situations.
- [[EgoLife Towards Egocentric Life Assistant]]：In order to realize an artificial intelligence-driven wearable glasses-based egocentric life assistant that can accompany and improve personal efficiency, the author team proposed the EgoLife project, and built the EgoLife dataset and EgoLifeQA benchmark, as well as the EgoButler system, aiming to solve the key technical challenges of egocentric artificial intelligence assistants and promote research in this field.
- [[PCE-GAN A Generative Adversarial Network for Point Cloud Attribute Quality Enhancement based on Optimal Transport]]：Proposes a new point cloud attribute quality enhancement algorithm called PCE-GAN (Point Cloud Attribute Quality Enhancement Generative Adversarial Network), which is based on optimal transport theory and aims to optimize both data fidelity and perceptual quality, thereby significantly improving the visual quality of compressed point clouds. The article concludes that PCE-GAN outperforms existing technologies in objective metrics (PSNR, BD-rate) and subjective visual quality (IWSSIMp), and shows better performance when processing point clouds with complex textures, which is more in line with actual application needs.
- [[OceanSim A GPU-Accelerated Underwater Robot Perception Simulation Framework]]：Proposes OceanSim, a GPU-accelerated underwater robot perception simulation framework, which can simulate underwater environments and multiple sensors with high fidelity, and is significantly superior to existing underwater simulators in rendering efficiency. The article aims to fill the research gap of existing underwater simulators in physical accuracy, rendering efficiency, and multi-sensor support, and provide a more effective and realistic tool for the development, testing, and verification of underwater robot perception algorithms. The core goal of OceanSim is to narrow the "sim-to-real gap" and promote the development of underwater robot technology.
- [[DELTA Dense Efficient Long-range 3D Tracking for any video]]：Proposes a new method called DELTA (Dense Efficient Long-range 3D Tracking for Any video), which for the first time realizes efficient, dense, and long-range 3D tracking of each pixel in any video, and achieves state-of-the-art accuracy while significantly improving speed. The global-local attention mechanism proposed by DELTA effectively balances computational efficiency and tracking accuracy, and can capture global motion while paying attention to local details, which is the core technology for achieving efficient dense tracking. The article emphasizes the significant impact of depth representation on 3D tracking performance, and experimental proof shows that log-depth representation is superior to traditional Euclidean depth, providing important insights for the input data representation of 3D vision tasks.

### Software and Development

The ideas and tools in the field of software development are also constantly evolving. From code philosophy to practical tools, how do these advances affect daily development?

"Every Line Is a Potential Bug" reminds developers that every line of code is a potential bug. You should only write code that is absolutely necessary and immediately needed, avoiding speculative programming and premature optimization. This concept is similar to Occam's Razor, YAGNI, and KISS principles.

Tailscale, as a remote device access tool, has gained wide recognition. It solves the problem of traditional DDNS and port forwarding failing in CGNAT environments, and provides port forwarding, file sharing, and other functions. For domestic users, consider deploying derper-docker and ip_derper as relay servers yourself.

In command-line tool usage, although the alias command is the traditional method for defining shell aliases, using scripts placed in the $PATH environment variable as aliases is usually a better choice, providing greater flexibility, maintainability, and scalability. For project management, Makefile is still a good unified entry point and encapsulation tool.

Other noteworthy developments include: elevator testing ideas inspiration (test design through finite state machine model), streaming HTML technology for creating real-time web applications, debugging strategies for device-side ML frameworks, Quartz static site generator, historical evolution of Unix file system, reflections on Python singleton pattern, MinerU high-quality data extraction tool, WebRTC audio AI SDK integration methods, and tutorials on implementing user-space TCP/IP protocol stacks.

- [[Every Line Is a Potential Bug]]：Every line of code is a potential bug. Therefore, unless absolutely necessary and immediately needed, do not write any code. The author emphasizes avoiding adding complexity to the code for speculative needs or premature optimization, because this will introduce unnecessary bug risks and may cause more serious problems in the future.
  - Every line of code is a potential bug: This is the core argument of the article, emphasizing the risk of code.
  - Avoid unnecessary code: In order to reduce bug risks, you should only write code that is absolutely necessary and immediately needed, avoiding speculative programming and premature optimization.
  - Simplicity is better than small performance improvements: When weighing the simplicity and performance of code, simplicity should be prioritized unless the performance bottleneck is very obvious and the optimization benefits far outweigh the risk of introducing complexity.
  - Note: Similar to Occam's Razor, YAGNI, and KISS principles, but the core assumptions and response methods of this article are worth discussing.
- [[Tailscale is pretty useful]]：Tailscale is very useful. It is a useful tool that can simplify remote device access and provides various convenient functions beyond traditional remote access methods. By sharing his own usage experience, the author emphasizes the value of Tailscale in solving the remote access problem in CGNAT environments and the additional value it provides in daily use.
  - Tailscale simplifies remote access in CGNAT environments: Tailscale solves the problem of traditional DDNS and port forwarding failing in CGNAT environments, allowing users to easily access devices located in home or office networks.
  - Tailscale provides multifunctional integration and user-friendly experience: In addition to basic remote access, Tailscale also integrates functions such as port forwarding, file sharing (Taildrop), VPN exit nodes, etc., and presents them in a user-friendly way, reducing the threshold for use.
  - Tailscale represents a new trend in personal network tools: Tailscale is not just a VPN, but a personal network management platform, indicating that personal network tools in the future will pay more attention to device interconnection, secure communication, and convenient operation.
  - Note:
    - Tailscale itself only provides foreign DERP relay servers. For domestic use, consider deploying [derper-docker](https://github.com/fredliang44/derper-docker) and [ip_derper](https://github.com/yangchuansheng/ip_derper) on cloud servers (fixed public IP) or broadband (dynamic public IP). The latter requires sacrificing some security. The control end can also self-build [headscale](https://github.com/juanfont/headscale).
    - Except for extremely complex NAT and MTU environments (such as school VPN), the connection is relatively stable. If punching through is successful, no relay server is needed; if not, forwarding is done through the relay server. Zerotier, which is similar to it, does not support self-built TCP relay, and moon nodes are actually just UDP relay nodes.
    - Further reading:
      - [[The New Internet - Tailscale's Vision for the Future of Connectivity]]
      - [[How NAT traversal works]]
      - [[浅探 Tailscale DERP 中转服务]]
- [[Why "alias" is my last resort for aliases]]：Although the `alias` command is the traditional method for defining shell aliases, using scripts placed in the `$PATH` environment variable (scripts in the `~/bin` directory) as aliases is usually a better choice because it provides greater flexibility, maintainability, and scalability. The author believes that scripts should be the default method for alias settings, and `alias` should only be used as a last resort in specific situations.
  - Script aliases are better than `alias` as the default choice: The author argues that due to the advantages of script aliases in flexibility, programmability, maintainability, and cross-platform compatibility, it should become the default method for alias settings, and `alias` should be relegated to the last choice in specific situations.
  - `alias` is still important in specific scenarios: The author acknowledges that `alias` has advantages in special shell functions (such as changing working directory), command completion, conditional definition, easy bypass, conciseness, and performance, so it is still irreplaceable in these specific scenarios.
  - Trade-offs in tool selection: The core idea of the article is to emphasize the trade-offs in tool selection, that is, there is no absolutely optimal tool. The choice should be based on specific needs and scenarios, and trade-offs need to be made between the advantages and disadvantages of different tools.
  - Note:
    - In addition to using alias and self-made scripts in the command line, writing Makefile for software projects is also a good unified entry point and encapsulation (whether it is Python, C++, or other languages), and it is convenient to pass in override parameters and automated tool calls. For example, in zetton-core, a long string of `colcon` commands for warehouse compilation, testing, code coverage checking, etc. is encapsulated into commands such as `make build`.
    - Further reading:
      - [[I Like Makefiles]]
      - [[How I stopped worrying and loved Makefiles]]
      - [[Makefile tricks for Python projects]]
- [[如何测试电梯 – 韩师傅就是我]]：Even without understanding the internal implementation principles of the system, effective system testing can be performed by building a computational model of the system (such as a finite state machine) and designing test cases based on this model. Taking the classic interview question "How to test an elevator" as an example, the article elaborates on the idea of using a finite state machine model for test design, emphasizing the importance of testing from the external logical behavior of the system.
  - Model abstraction simplifies complexity: Facing complex system testing, even without understanding the internal implementation, abstract models such as finite state machines can be built to grasp the core logic of the system and reduce the complexity of test design.
  - Logical behavior testing priority: Testing should focus on verifying whether the external logical behavior of the system meets expectations, rather than over-relying on internal implementation details. Starting from the user's perspective and paying attention to system state changes and event responses is key.
  - Model-driven improves testing efficiency: Using models (such as finite state machines) can systematically guide test case design, ensure test coverage, and improve test efficiency and quality.
- [[The Cursed Art of Streaming HTML – rinici.de]]：Streaming HTML is a feasible technology that can be used to create real-time web applications without over-reliance on JavaScript. The author believes that by leveraging the browser's support for `Connection: keep-alive` and server-side streaming capabilities, real-time update effects similar to WebSocket or SSE can be achieved, but the implementation method is simpler and reduces the reliance on JavaScript to a certain extent.
- [[Debugging Disposable ML Frameworks]]：When developing and debugging disposable machine learning frameworks for device-side deployment, adopting modular testing, intermediate tensor comparison, focusing on quantization, and maintaining a clear cognitive model are essential debugging strategies. The author emphasizes that although there are many resources on training Transformer models, debugging guidance for device-side deployment is relatively lacking. Therefore, he shares practical experience and techniques accumulated in the process of building such frameworks, aiming to help developers avoid common pitfalls and debug more effectively.
  - Special features and challenges of device-side ML framework debugging: Unlike model training, debugging for device-side deployment lacks sufficient resources and guidance, requiring developers to master specific debugging skills.
  - Modularization and intermediate tensor comparison are effective debugging strategies: By decomposing the model into modules and comparing the intermediate tensors of known good models and custom frameworks, error modules can be quickly located and debugging efficiency can be improved.
  - Clear cognitive model is the basis for efficient debugging: Developers need to deeply understand the model architecture, algorithm principles, and implementation details in order to effectively debug and solve problems.
- [quartz](https://github.com/jackyzha0/quartz)：Quartz is a fast, batteries-included static-site generator that transforms Markdown content into fully functional websites.
- [[50 years in filesystems 1974  Die wunderbare Welt von Isotopp]]：Although the Unix V7 file system was born in 1974 and was limited by the hardware conditions at the time, there are many limitations, but the core concepts and structures in its design are very clear and concise, and have had a profound impact on later file systems and even the POSIX standards of modern operating systems. By reviewing the key components and design decisions of the Unix V7 file system, the article shows the basic principles of early file systems, and reflects on the essence of technological progress and the continuous influence of early designs on modern systems.
- [[50 years in filesystems 1984  Die wunderbare Welt von Isotopp]]：The BSD Fast File System (FFS) released in 1984 is an important improvement to the traditional Unix file system. By introducing a number of innovative designs, it significantly improved the performance and efficiency of the file system to adapt to the rapidly developing hardware and user needs at that time. By reviewing the design background, core innovations, and performance improvements of BSD FFS, the article demonstrates its milestone significance in the history of file system development.
- [[再也别问 Singleton 了好吗？]]：In the Python language, Singleton (singleton pattern) is usually unnecessary and often misused. A simpler and more Python-philosophical way is to use module-level variables to achieve singleton needs. The author believes that Singleton, as a classic design pattern, does not have the necessity in Python that it has in other languages. On the contrary, its complexity leads to misuse and becomes an interview cliché.
- [MinerU](https://github.com/opendatalab/MinerU)：One-stop open-source high-quality data extraction tool, converting PDF to Markdown and JSON formats.
- [[Integrating Audio AI SDK with WebRTC (1) A Look Inside WebRTC's Audio Pipeline]] and [[Integrating the Audio AI SDK into WebRTC (2) Methodology for Building a Testing Environment for Effective Integration Development]]：When integrating audio AI SDK (such as Gaudio Lab's GSEP-LD) in WebRTC, building a robust and efficient testing environment is crucial, which is directly related to the effectiveness of integration development and the final effect. The article emphasizes that due to the complexity of the WebRTC Audio Processing Module (APM) and the diversity of integration point selection, as well as the potential influence of various environmental factors and submodule interactions, careful and thorough testing is a key step to ensure successful integration. The article further points out that using command-line interface (CLI) tools and open-source projects can effectively simplify the construction and management of the test environment, so as to cope with the integration testing needs in complex scenarios.
- [[Let's code a TCPIP stack, 1 Ethernet & ARP]]：Implementing a minimal user-space TCP/IP protocol stack, starting from Ethernet and ARP, is an effective educational method for learning network and system programming. Through practical code examples and steps, the article shows how to use Linux TAP devices to capture network packets, and parse Ethernet frames and ARP protocol, and finally successfully implement ARP responses, verifying this argument. The article aims to illustrate that even though the TCP/IP protocol stack looks complex, it is feasible to start with basic protocols such as Ethernet and ARP and implement them step by step, and it is very helpful for in-depth understanding of the working principles of the network protocol stack.
- [[Let's code a TCPIP stack, 2 IPv4 & ICMPv4]]：It is feasible to implement a minimal usable TCP/IP protocol stack including IPv4 and ICMPv4 layers in user space, and it can be verified by ICMP echo request (ping). The article aims to show the practical method of building a network protocol stack, and encourage readers to understand the basic principles and implementation details of IPv4 and ICMPv4.
- [[Let's code a TCPIP stack, 3 TCP Basics & Handshake]]：Understanding the basic principles of the TCP protocol, especially its reliability mechanism and three-way handshake process, is a key step in building a TCP/IP protocol stack. Through theoretical introduction, protocol header analysis, and detailed explanation of the handshake process, combined with code testing, the article gradually shows the implementation method and verification process of the TCP handshake function in the TCP protocol stack. The ultimate goal is to lay the foundation for readers to understand the construction of the TCP protocol stack and pave the way for subsequent implementation of reliable data transmission functions.

### Project and Team Management

- [[A few words about indie app business – Charlie Monroe]]：Indie app business is a marathon, not a sprint. Success requires long-term persistence, continuous iteration, and adaptation to change.
  - Patience and iteration: Don't expect overnight success. Start small, iterate quickly, and continuously improve products based on user feedback.
  - Necessity of long-term investment: Indie app business requires long-term investment of time and energy. It is difficult to balance with full-time work. Be prepared for long-term hard work.
  - Risk awareness and diversification: The industry is changing rapidly, and apps may face the risk of being eliminated. Maintain risk awareness and diversify development to reduce risks.
- [[Your Next Two Zeroes]]：Scaling up by one order of magnitude (10x) can usually be adjusted through existing methods and tools, but scaling up by two orders of magnitude (100x) will completely subvert the problem domain, forcing us to rethink all aspects, including methods, tools, skills, and mindsets. This scale leap is not just a quantitative accumulation, but a qualitative change. It requires abandoning the original "secrets of success" and facing it with a completely new perspective and method.
  - Critical point of scale leap: The core argument of the article is that scaling up by two orders of magnitude (100x) is a key critical point that will trigger systemic qualitative changes, rather than just quantitative accumulation.
  - Failure of original methods: With the leap in scale, the original effective "secrets of success" and methodology will fail, and even become "bad instincts" that hinder progress.
  - Transformation of cognitive patterns: The key to coping with scale leaps lies in the transformation of cognitive patterns. It is necessary to abandon inherent mindsets and learn and adapt to new challenges with the mentality of "becoming a novice again."
- [[A Founder's Guide Essential Management Advice for Startups by @ttunguz]]：Effective management is crucial for startups to move from chaotic growth to sustainable success. Management is not an innate talent, but a discipline that can be learned, practiced, and improved. The article emphasizes that as startups scale, the importance of management ability is as important as the expansion of technology or customer base.

### Knowledge Management

- [[为什么笔记用户要保卫自己的「数字主权」？ - 少数派]]：In the digital age, personal knowledge bases have become important digital assets. Users need to have complete control over their note data to avoid data loss, platform monopoly, and limitations brought by future technological developments.
  - Note users should defend digital sovereignty: The core argument is that users should have complete control over their note data to avoid platform monopolies, data loss, and future technology restrictions. This is the basis of knowledge management and knowledge compounding.
  - Open source format + multi-terminal backup is the key strategy to ensure digital sovereignty: It is recommended to use open source plain text formats (such as Markdown) as the note carrier, and adopt multi-terminal synchronization backup solutions (such as Git) to ensure data security, portability, and long-term availability.
  - Digital sovereignty is a prerequisite for knowledge compounding in the AI era: Emphasizes that in the era of rapid development of AI technology, mastering digital sovereignty, especially using plain text formats, can better utilize personal knowledge bases, enjoy new technology dividends, and maximize knowledge compounding.
- [[从 Pandoc 到 Quarto：纯文本学术写作的实践与优化 - 少数派]]：Quarto, as the next-generation scientific publishing system based on Pandoc, provides more powerful functions and more user-friendly user experience, such as code execution, cross-references, reference previews, etc., as well as optimization schemes for Chinese academic writing. It is a more ideal plain text academic writing tool than Pandoc, which can significantly improve the efficiency and experience of academic writing, and ultimately allow authors to focus more on the content itself and produce higher quality academic achievements.
  - Note: Markdown is sufficient for daily technical writing, but LaTeX is still needed for academic papers.
- [[人工智能真能替你写作吗？我自己的「AI 蓝军」测试]]：Artificial intelligence (especially generative AI) has shown strong capabilities in the field of writing, and can assist or even partially replace humans in completing writing tasks, but this does not mean that human writers will be completely replaced. The article emphasizes that in the AI era, knowledge workers need to actively adapt to changes, master AI tools, and use them as assistants to improve productivity, focusing on human unique thinking, values, and aesthetic judgments, in order to maintain competitiveness in the future content production field. Through the author's own "AI Blue Army" testing experience, the application potential of AI in the writing process is verified, and the positioning and development direction of human writers in the AI era are discussed.
  - In-depth research phase:
    - Topic selection: The author first selected the MCP protocol that he was interested in as the topic
    - Use OpenAI Deep Research: Submit clear questions and let AI conduct in-depth research
    - Generate original report: Obtain detailed and comprehensive research reports, but with obvious "AI flavor"
  - Structure optimization phase:
    - Use Claude 3.7 Sonnet: This model is good at processing long texts and has strong instruction following ability
    - Structure adjustment strategy: Through carefully designed prompts, let AI reorganize the content structure
    - Generate structured content: Output article frameworks that are more in line with the author's style, but still have some AI features
  - Style polishing phase:
    - Use ChatGPT 4.5: This model performs excellently in style imitation
    - Segmented processing strategy: Adopt multi-round dialogue method to avoid compression and quality degradation caused by one-time processing
    - Style polishing prompts: Accurately describe language style, reader address, punctuation usage, and other detailed requirements
    - Generate natural articles: Output high-quality articles that are almost indistinguishable from AI writing
  - Image generation phase:
    - Use ChatGPT 4.0: Generate matching cover images based on article content
    - Final review: The author made simple modifications and deleted redundant summary remarks
- [[从素材到成文，揭秘 Dailyio 的大模型写作全流程｜Digital Explorer055]]：Large models can effectively empower the workflow of content creators, but they do not replace humans, but rather a human-machine collaboration model. The article emphasizes that in serious writing and industry analysis and other scenarios, large models still require deep human intervention, especially in material discovery, data preparation, and style guidance. By sharing his own workflow for producing content for the "AI Insider" email newsletter, the author specifically shows how to use large models to improve efficiency, process information, and imitate writing styles. However, it also warns of the risks of completely relying on large models, emphasizing the key role of high-quality input (materials and instructions) for output quality.
  - Get materials: Efficiently obtain text materials using modern browser tools
    - Use Chromium-based browsers such as Brave
    - Use bypass paywalls clean extension to bypass paywalls
    - Use MarkDownload to convert web pages to Markdown format
    - Manage materials in Obsidian in an orderly manner
  - Process materials: Choose different prompt strategies according to material types
    - News: Use "Socratic questioning method" prompts
    - Opinions: Use "Enrich" prompts
  - Style learning: Let large models learn the author's personal writing style
    - Select representative writing samples (300-400 words/article)
    - Use prompts of "imitate style in stages to write"
    - Let the model analyze and confirm style characteristics
  - Implement writing: Create based on materials and style
    - Prepare materials and outlines
    - Choose a suitable model (Claude series is recommended)
    - Interact with the model through API
    - Execute a five-step writing process to complete creation

### ACGN

- [[桌游设计杂记（5）  用三个月，测试并编辑一个重度的战棋游戏 - 少数派]]：Successfully developing a heavy strategy board game and making it reach the point where it can be submitted to overseas publishers requires detailed division of labor and cooperation, high-intensity internal testing and iteration, and attention to productization and editing. By recording the development process of the game "Qi Wei Chun Qiu" in three months, the article specifically elaborates on how to overcome the difficulty of tight time through efficient internal testing, timely version iteration, multilingual preparation, rulebook writing, and productization preparation, and finally produce game samples that can be used for submission. At the same time, the article also emphasizes that board game development is not just about gameplay and art, but also includes prototyping, testing, rulebook, editing, production, and other links, which requires team collaboration and professional division of labor to ensure quality and efficiency.

### Podcasts

- [后互联网时代的乱弹] 第 153 期 Global Representative Offices in China
- [编码人声] Chatting about various peripherals, the anchors' treasure trove of good things
- [晚点聊 LateTalk] 105: Lu Chen You Yang talks about third-party cloud platform DeepSeek cost in controversy: Why I don't do MaaS anymore?
- [晚点聊 LateTalk] 104: 3700 pre-training sessions to find non-consensus, MiniMax-01 developer tells the story of 4-year linear attention journey
- [忽左忽右] 389 Wong Kar-wai's film world and Shanghai-Hong Kong imagination in the 1960s
- [科技乱炖] We witnessed the largest hacker theft in human history
- [硬地骇客] EP95 Dialogue with ByteDance Trae team: Exploring the evolution path of AI IDE
- [张小珺 Jùn｜商业访谈录] 95. 3-hour interview with Xiao Hong: Agent, 2 years of AI application entrepreneurship, being an "important variable in the game"
- [OnBoard!] EP 67. Analysis of DeepSeek R1 technical innovation and ecological impact: Reinforcement learning, Long CoT, data, Agent and open source ecology
- [硅谷 101] E182｜Shadow Dollar and New Financial Order: Uncovering Tether, the world's most profitable company per capita
- [半拿铁 | 商业沉浮录] No.140 Layoff wave in the 1990s
